{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa2af56b-3bba-4856-ba4e-0b964ae90e3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "\n",
    "demo = \"PhotonPerformance\"\n",
    "\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "userhome = f\"dbfs:/user/{username}/{demo}\"\n",
    "database = f\"\"\"{demo}_{re.sub(\"[^a-zA-Z0-9]\", \"_\", username)}_db\"\"\"\n",
    "\n",
    "print(f\"\"\"\n",
    "username: {username}\n",
    "userhome: {userhome}\n",
    "database: {database}\"\"\")\n",
    "\n",
    "spark.sql(f\"SET c.userhome = {userhome}\")\n",
    "\n",
    "dbutils.widgets.text(\"mode\", \"cleanup\")\n",
    "mode = dbutils.widgets.get(\"mode\")\n",
    "\n",
    "\n",
    "if mode == \"reset\":\n",
    "    spark.sql(f\"DROP DATABASE IF EXISTS {database} CASCADE\")\n",
    "    dbutils.fs.rm(userhome, True)\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {database} LOCATION '{userhome}'\")\n",
    "    spark.sql(f\"USE {database}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e027168-e9ab-4a05-aabe-001f8e751ccf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def check_files(table_name):\n",
    "    filepath = spark.sql(f\"DESCRIBE EXTENDED {table_name}\").filter(\"col_name == 'Location'\").select(\"data_type\").collect()[0][0]\n",
    "    filelist = dbutils.fs.ls(filepath)\n",
    "    filecount = len([file for file in filelist if file.name != \"_delta_log/\" ])\n",
    "    print(f\"Count of all data files in {table_name}: {filecount}\\n\")\n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4056260-83b4-4697-a981-a6ea47402008",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if mode == \"cleanup\":\n",
    "    spark.sql(f\"DROP DATABASE IF EXISTS {database} CASCADE\")\n",
    "    dbutils.fs.rm(userhome, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de41a9d5-1045-46b4-9e6e-1c4dfa8613d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if mode == \"reuse\":\n",
    "    spark.sql(f\"USE {database}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00-setup",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
